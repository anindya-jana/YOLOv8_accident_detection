{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84b4afd0",
   "metadata": {},
   "source": [
    "# Yolo real-time accident detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2f8f8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#run this cell only\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from cap_from_youtube import cap_from_youtube \n",
    "import uuid\n",
    "import datetime\n",
    "import torch\n",
    "\n",
    "#enter your video link\n",
    "url=\"https://www.youtube.com/watch?v=CTQErltXZqM\"#example\n",
    "\n",
    "source_error=False\n",
    "try:\n",
    "    if 'yout' in url:#if the url is from youtube then using cap_from_youtube package to import video\n",
    "        cap = cap_from_youtube(url, 'best')  \n",
    "    else:\n",
    "        vurl=url+\"/video\"\n",
    "        cap = cv2.VideoCapture(vurl)\n",
    "except:\n",
    "    print(\"Camera_source_error\")    \n",
    "    source_error=True  \n",
    "\n",
    "width  = cap.get(3)\n",
    "height = cap.get(4)\n",
    "print('width, height:', width, height)\n",
    "video_area=width*height\n",
    "if int(video_area) == 0:\n",
    "    print(\"Camera_source_error\")     \n",
    "    source_error=True            \n",
    "\n",
    "if not source_error:      \n",
    "    try:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        #moderate accuracy but require medium hardware for realtime at 720p i.e RTX 4050 \n",
    "        model = YOLO('yolov8m.pt')\n",
    "        #more accurate results but requires good hardware for realtime at 720p i.e RTX 4070Ti \n",
    "        #model = YOLO('yolov8x.pt')\n",
    "        model.to(device=device)\n",
    "    except:\n",
    "        print(\"YOLO_model_loading_error\")\n",
    "    track_history = defaultdict(lambda: [])# Store the track history\n",
    "    speed_history = defaultdict(lambda: [])# Store the relative history\n",
    "    frame_skipper=0\n",
    "\n",
    "    obj=[-1,-1]\n",
    "\n",
    "    while cap.isOpened() :\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(30) & 0xFF == ord(\"q\"):\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows() \n",
    "            break\n",
    "\n",
    "        success, frame = cap.read()\n",
    "        if success:\n",
    "            #tracking only cars,trucks,buses,motorcycle and have a confidence more than 0.7\n",
    "            results = model.track(frame,conf=0.75, classes=[1,2,3,5,7],persist=True)\n",
    "            boxes = results[0].boxes.xywh\n",
    "            try:\n",
    "                class_ids=results[0].boxes.cls\n",
    "                track_ids = results[0].boxes.id.int().tolist()\n",
    "            except:\n",
    "                track_ids=None\n",
    "\n",
    "            annotated_frame = results[0].plot()\n",
    "\n",
    "            if track_ids is not None:\n",
    "                for box, track_id ,class_id in zip(boxes, track_ids,class_ids):\n",
    "                    min_dist=1000\n",
    "                    x, y, w, h = box        \n",
    "                    area=float(w)* float(h)\n",
    "                    track = track_history[track_id]\n",
    "                    track.append((float(x), float(y)))  # x, y center point\n",
    "                    if len(track) > 15:  # retain 7 tracks for 7 frames \n",
    "                        track.pop(0)\n",
    "\n",
    "                    for box1, track_id1 ,class_id1 in zip(boxes, track_ids,class_ids):\n",
    "                        if track_id != track_id1:#skipping its own track id\n",
    "                            x1, y1, w1, h1 = box1\n",
    "                            area1=float(w1)* float(h1)\n",
    "                            point=(float(x), float(y))\n",
    "                            point1=(float(x1), float(y1))\n",
    "                            dist=(math.dist(point,point1))/((math.sqrt(area)+math.sqrt(area1))/2)\n",
    "                             #relative distance between the points       \n",
    "                            if dist<min_dist:\n",
    "                                min_dist=dist\n",
    "                                obj[0]=int((class_id))\n",
    "                                obj[1]=int((class_id1))\n",
    "                    # Draw the tracking lines\n",
    "                    points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
    "                    distance_draw=math.dist(track[0],track[-1])\n",
    "                    if distance_draw==0:\n",
    "                        relative_speed=0\n",
    "                    else:    \n",
    "                        relative_speed=distance_draw/area\n",
    "\n",
    "                    speed=speed_history[track_id]   \n",
    "                    speed.append(relative_speed)\n",
    "                    if len(speed) > 5:  # retain 5 tracks for 5 frames \n",
    "                        speed.pop(0)\n",
    "\n",
    "                    speed_difference=speed[-1]-speed[0]\n",
    "\n",
    "                    if speed_difference==0:\n",
    "                        acceleration=0\n",
    "                    else:    \n",
    "                        acceleration=speed_difference /len(speed)  \n",
    "\n",
    "                    #print( results[0].names)\n",
    "                    cv2.polylines(annotated_frame, [points], isClosed=False, color=(230, 230, 230), thickness=5)\n",
    "                    cv2.putText(annotated_frame,str(int(relative_speed*10000)),(int(x-(w/2)), int((h/2)+y)),cv2.FONT_HERSHEY_SIMPLEX ,1, (0, 225, 0),2,cv2.LINE_AA)\n",
    "                    cv2.putText(annotated_frame,str(int(abs(acceleration)*20000)),(int(x+(w/2)), int((h/2)+y)),cv2.FONT_HERSHEY_SIMPLEX ,1, (0, 0, 225),2,cv2.LINE_AA)\n",
    "                    cv2.putText(annotated_frame,str(int(min_dist*100)),(int(x), int((h/2)+y)),cv2.FONT_HERSHEY_SIMPLEX ,1, (225,0, 25),2,cv2.LINE_AA)\n",
    "                    #changing the values may vary the detection of accident\n",
    "                    if ((relative_speed*10000)>7) and ((min_dist*100)<120)and ((abs(acceleration)*20000)>3):#during accident the car should have some speed and it should have some accident                            \n",
    "                        if frame_skipper>0:\n",
    "                            frame_skipper=frame_skipper-1\n",
    "                            continue\n",
    "                        else: \n",
    "                            frame_skipper=25#skips accident detection for 25 frames after an accident is detected\n",
    "\n",
    "                        #cv2.putText(annotated_frame,\"Accident\",(int(x-(w/4)), int(y)),cv2.FONT_HERSHEY_SIMPLEX ,1, (12,0,225),2,cv2.LINE_AA)\n",
    "                        accident_id = str(uuid.uuid1())#Gets a new unique id at every acciddent\n",
    "                        cropped_image = annotated_frame[int(y-(h*1.5)):int(y+(h*1.5)), int(x-(w*1.5)):int(x+(w*1.5))]\n",
    "                        cv2.imwrite(\"accident_{}.jpg\".format(accident_id), annotated_frame)#saves the file in your loacl machine\n",
    "                        cv2.imwrite(\"accident_{}.jpg\".format(accident_id), cropped_image)#rewrite the file after cropped,if cropping is successful\n",
    "\n",
    "\n",
    "            # Display the annotated frame\n",
    "            cv2.imshow(\"YOLOv8 Tracking\", annotated_frame)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaca268",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# install packages for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c532aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you want to run on CPU just install this\n",
    "!pip install opencv-python\n",
    "!pip install ultralytics\n",
    "!pip install cap-from-youtube\n",
    "!pip install youtube_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44819b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you want to run on gpu\n",
    "#install cuda 12.1 from nvidia if not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e99cd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0728d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch==2.1.1 torchvision==0.16.1 torchaudio==2.1.1 --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e65904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchaudio\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "print(torchaudio.__version__)\n",
    "#if it shows like this then ok\n",
    "#2.1.1+cu121\n",
    "#0.16.1+cu121\n",
    "#2.1.1+cu121\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
